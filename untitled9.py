# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EXlIFVbtS43ik0JuzYkszwZFjI_cI4Sz
"""

import numpy as np
import matplotlib.pyplot as plt

import keras

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout  #Dropout---used to prevent overfitting

"""get data and preprocess

"""

#mnist.load_data  #? is to know what dataset is loaded
(X_train, y_train), (X_test, y_test)= mnist.load_data()
X_train.shape, y_train.shape , X_test.shape , y_test.shape

plt.imshow(X_train[0])

plt.imshow(X_train[0], cmap= 'binary')

def plot_input_img(i):
    plt.imshow(X_train[i], cmap= 'binary')
    plt.title(y_train[i])    # labels
    plt.show()
for i in range(10):    #print first 10 images of dataset
    plot_input_img(i)

"""Pre-process the image"""

#normalizing the image to [0,1] range

X_train = X_train.astype(np.float32)/255   # dividing by 255 to normalize it
X_test = X_test.astype(np.float32)/255

X_train.shape

# Reshape/Expand dimensions of image to (28,28,1)

X_train =  np.expand_dims(X_train, -1)
X_test =  np.expand_dims(X_test, -1)
X_train.shape

#convert classes to one-hot vectors

y_train= keras.utils.to_categorical(y_train)

y_test= keras.utils.to_categorical(y_test)
y_train

model = Sequential()

model.add(Conv2D(32, (3,3), input_shape = (28,28,1) , activation= 'relu'))  #first convolution layer
#                                                                              32--number of units,    (3x3)--kernel size. (3,3)is industrial standard.
model.add(MaxPool2D(2,2))    #pool size 2x2

#adding  2 more convolution layers
model.add(Conv2D(64, (3,3), activation= 'relu'))
model.add(MaxPool2D(2,2))

model.add(Flatten())

model.add(Dropout(0.25))   #used to prevent overfitting 0.5--50% of it, or 25% upto you

model.add(Dense(10,activation="softmax"))   #dense layer is used for classification and number of classes here is 10 i.e from 0-9.
model.summary()

#compile
model.compile(optimizer='adam', loss = keras.losses.categorical_crossentropy, metrics=['accuracy'])
#Callbacks

from keras.callbacks import EarlyStopping, ModelCheckpoint

#EarlyStopping
es= EarlyStopping(monitor='val_acc', min_delta=0.01, patience=4, verbose=1)

#model check point
mc= ModelCheckpoint("./bestmodel.h5", monitor="val_acc", verbose=1, save_best_only= True)

cb= [es,mc]  #Callback

model.save('bestmodel.h5')

his = model.fit(X_train,y_train, epochs=10, validation_split=0.3, callbacks=cb)# 50 --since we hv earlystopping here, we dont hv to worry abt model overfitting or not. apart from that we can give validation_split.
#                                                                    validati

model_S = keras.models.load_model("C://Users//DELL-PC//Downloads//projecttt//bestmodel//bestmodel.h5")
score = model_S.evaluate(X_test, y_test)

print(f" The model accuracy is {score[1]} ")